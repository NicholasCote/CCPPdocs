{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the CISL Cloud Pilot Project (CCPP) Follow our up to date Kanban . Pilot This is currently a Pilot project. Determining long term feasibility is one of our objectives. Vision Provide and operate an on-premise cloud offering for the scientific community to supplement traditional HPC services and public cloud offerings while utilizing 2i2c to host a JupyterHub instance in the public cloud. What is an on-premise cloud? NCAR | CISL runs Compute, Storage & Network hardware in robust Data Centers at multiple organizational facilities. An on-premise cloud is offering users the ability to utilize those highly available organizationally supported compute resources for approved use cases. This includes access to routable network space and UCAR Domain Name Systems (DNS). Security standards set by the organization are These resources would be provided to supplement computing needs that aren't fulfilled by the HPC offering, public cloud, or what is available to you locally. Goals Improve understanding of how scientific community might use and benefit from an on-prem cloud Which services fit on-prem better than traditional HPC and/or public cloud Gain experience within CISL deploying and operating an on-prem cloud and associated services Improve CISL ability to support interactive analysis workflows in environment where data is globally distributed Increase user visibility in to on-prem cloud offerings Develop metrics to showcase project value & feasibility Gain experience with Agile Project Management","title":"Home"},{"location":"#welcome-to-the-cisl-cloud-pilot-project-ccpp","text":"Follow our up to date Kanban .","title":"Welcome to the CISL Cloud Pilot Project (CCPP)"},{"location":"#pilot","text":"This is currently a Pilot project. Determining long term feasibility is one of our objectives.","title":"Pilot"},{"location":"#vision","text":"Provide and operate an on-premise cloud offering for the scientific community to supplement traditional HPC services and public cloud offerings while utilizing 2i2c to host a JupyterHub instance in the public cloud.","title":"Vision"},{"location":"#what-is-an-on-premise-cloud","text":"NCAR | CISL runs Compute, Storage & Network hardware in robust Data Centers at multiple organizational facilities. An on-premise cloud is offering users the ability to utilize those highly available organizationally supported compute resources for approved use cases. This includes access to routable network space and UCAR Domain Name Systems (DNS). Security standards set by the organization are These resources would be provided to supplement computing needs that aren't fulfilled by the HPC offering, public cloud, or what is available to you locally.","title":"What is an on-premise cloud?"},{"location":"#goals","text":"Improve understanding of how scientific community might use and benefit from an on-prem cloud Which services fit on-prem better than traditional HPC and/or public cloud Gain experience within CISL deploying and operating an on-prem cloud and associated services Improve CISL ability to support interactive analysis workflows in environment where data is globally distributed Increase user visibility in to on-prem cloud offerings Develop metrics to showcase project value & feasibility Gain experience with Agile Project Management","title":"Goals"},{"location":"how-to/agile/","text":"Agile Interaction The CCPP team is utilizing hybrid Agile Project Management strategies (Kanban & Waterfall) to manage development. What is Agile Project Management? At a high level Agile is a framework that focuses on interaction, collaboration, and visibility in order to predictably deliver working product that meets all customer requirements. What is Waterfall? Waterfall methodology is a project management approach that maps out a project into distinct phases. The CCPP team will be utilizing Waterfall to manage overall project status and track deliverables. The current Waterfall smartsheet rollup can be viewed here . What is Kanban? Kanban is a flexible Agile framework with a focus on continuous delivery. Individual work items are called User Stories and are represented visually on a Kanban Board. What are User Stories? An informal explanation of a feature written from the perspective of the end user. The goal is to keep this short and simple so that it can be accomplished in a few days. If it will take more than a few days the issue needs to be looked at in more detail and broken down in to smaller batch sizes. This allows for a continuous feedback loop where small pieces of overall functionality are demonstrated to the user base. These small pieces of functionality are defined in the User Stories Acceptance Criteria. What is Acceptance Criteria? In order to make sure the User Story has a clear definition of being done the PO will define Acceptance Criteria. It is written from a user perspective and defines a requirement, why it is needed, and what expectations are for successful completion. Example: As a CCPP User I want to understand what Acceptance Criteria is so that I can ensure my completed user story meets my expectations of done. How do I interact with the team? Via the Agile Product Owner (PO) All requests & questions can be directed to the Product Owner (PO) for the project. Nick Cote is the Agile Product owner for this project. The Agile PO's responsibility is representing the customer and stakeholder and is their interface to the development team. This allows the development team members to focus on delivering valuable working product while the customer is still being accurately represented via the PO. All requests directed at the PO will be turned in to user stories on our Kanban Board. Kanban Board Issues can also be created in Jira and added to our Kanban backlog. The PO will ensure your request is understood and has valid acceptance criteria. It will then be prioritized appropriately against other tasks in the queue. The CCPP Kanban board currently implements the follow story states: Backlog # New stories that have not yet been fully reviewed and prioritized To Do # Stories have been reviewed and prioritized Stalled # Work is on hold for various reasons In Progress # A team member is actively working the Story In Review # PO will check to make sure the Story Acceptance Criteria is met Done # Acceptance Criteria has been verified successfully and the Story is complete User Stories are self-assigned by a team member who wants to accomplish the task. A User Story will move from a status of To Do \u2192 In Progress when it is the at the top of the Assignee's To Do list and they are ready to start. Kanban utilizes Work In Progress (WIP) limits to help identify bottlenecks and promoting moving tasks to Done . The CCPP has implemented the following WIP limits: Stalled : 4 In Progress : 6 In Review : 4 Demonstrations As new functionality is rolled out we will be taking advantage of different platforms to demonstrate working products to our stakeholders. Feedback is strongly desired during these demonstrations in order to ensure what the team is delivering is accurately meeting the user requirements. These interactions make sure the team is continuously improving. Retrospectives Once a month the team will look back on the process overall. The focus will be on what has been working, what hasn't been working, and what improvements should we try in order to improve the process for our workflow.","title":"Agile Interaction"},{"location":"how-to/agile/#agile-interaction","text":"The CCPP team is utilizing hybrid Agile Project Management strategies (Kanban & Waterfall) to manage development.","title":"Agile Interaction"},{"location":"how-to/agile/#what-is-agile-project-management","text":"At a high level Agile is a framework that focuses on interaction, collaboration, and visibility in order to predictably deliver working product that meets all customer requirements.","title":"What is Agile Project Management?"},{"location":"how-to/agile/#what-is-waterfall","text":"Waterfall methodology is a project management approach that maps out a project into distinct phases. The CCPP team will be utilizing Waterfall to manage overall project status and track deliverables. The current Waterfall smartsheet rollup can be viewed here .","title":"What is Waterfall?"},{"location":"how-to/agile/#what-is-kanban","text":"Kanban is a flexible Agile framework with a focus on continuous delivery. Individual work items are called User Stories and are represented visually on a Kanban Board.","title":"What is Kanban?"},{"location":"how-to/agile/#what-are-user-stories","text":"An informal explanation of a feature written from the perspective of the end user. The goal is to keep this short and simple so that it can be accomplished in a few days. If it will take more than a few days the issue needs to be looked at in more detail and broken down in to smaller batch sizes. This allows for a continuous feedback loop where small pieces of overall functionality are demonstrated to the user base. These small pieces of functionality are defined in the User Stories Acceptance Criteria.","title":"What are User Stories?"},{"location":"how-to/agile/#what-is-acceptance-criteria","text":"In order to make sure the User Story has a clear definition of being done the PO will define Acceptance Criteria. It is written from a user perspective and defines a requirement, why it is needed, and what expectations are for successful completion. Example: As a CCPP User I want to understand what Acceptance Criteria is so that I can ensure my completed user story meets my expectations of done.","title":"What is Acceptance Criteria?"},{"location":"how-to/agile/#how-do-i-interact-with-the-team","text":"","title":"How do I interact with the team?"},{"location":"how-to/agile/#via-the-agile-product-owner-po","text":"All requests & questions can be directed to the Product Owner (PO) for the project. Nick Cote is the Agile Product owner for this project. The Agile PO's responsibility is representing the customer and stakeholder and is their interface to the development team. This allows the development team members to focus on delivering valuable working product while the customer is still being accurately represented via the PO. All requests directed at the PO will be turned in to user stories on our Kanban Board.","title":"Via the Agile Product Owner (PO)"},{"location":"how-to/agile/#kanban-board","text":"Issues can also be created in Jira and added to our Kanban backlog. The PO will ensure your request is understood and has valid acceptance criteria. It will then be prioritized appropriately against other tasks in the queue. The CCPP Kanban board currently implements the follow story states: Backlog # New stories that have not yet been fully reviewed and prioritized To Do # Stories have been reviewed and prioritized Stalled # Work is on hold for various reasons In Progress # A team member is actively working the Story In Review # PO will check to make sure the Story Acceptance Criteria is met Done # Acceptance Criteria has been verified successfully and the Story is complete User Stories are self-assigned by a team member who wants to accomplish the task. A User Story will move from a status of To Do \u2192 In Progress when it is the at the top of the Assignee's To Do list and they are ready to start. Kanban utilizes Work In Progress (WIP) limits to help identify bottlenecks and promoting moving tasks to Done . The CCPP has implemented the following WIP limits: Stalled : 4 In Progress : 6 In Review : 4","title":"Kanban Board"},{"location":"how-to/agile/#demonstrations","text":"As new functionality is rolled out we will be taking advantage of different platforms to demonstrate working products to our stakeholders. Feedback is strongly desired during these demonstrations in order to ensure what the team is delivering is accurately meeting the user requirements. These interactions make sure the team is continuously improving.","title":"Demonstrations"},{"location":"how-to/agile/#retrospectives","text":"Once a month the team will look back on the process overall. The focus will be on what has been working, what hasn't been working, and what improvements should we try in order to improve the process for our workflow.","title":"Retrospectives"},{"location":"how-to/build-docs/","text":"How to build this documentation 1. Make sure you have MkDocs installed pip install mkdocs 2. Clone the git repository git clone https://github.com/NCAR/cisl-cloud.git 3. Change in to docs/directory cd docs/ 4. Serve content with MkDocs mkdocs serve Documentation file structure mkdocs.yml # The configuration file. docs/ css/ extra.css # Contains extra sytling for the site. how-to/ agile.md # A description of the teams current Agile practices and policies build-docs.md # A how-to on building the documentation website images/ * # All custom images used in the site img/ favicon.ico # Overrides the default images used by readthedocs theme js/ clipboard.js # Javascript to copy code to the clipboard extra.js # Defining how to implement the clipboard copy in our HTML popper.min.js # Used to have the Copied pop up on click tippy-bundle.umd.js # Used to have the Copied pop up on click about.md # The project about trading contact.md # How to interact with the team features.md # A list of potential features for the project index.md # The documentation homepage. layout.md # Outline of site directories and files services.md # List of potential services we will offer","title":"Documentation Site Build"},{"location":"how-to/build-docs/#how-to-build-this-documentation","text":"","title":"How to build this documentation"},{"location":"how-to/build-docs/#1-make-sure-you-have-mkdocs-installed","text":"pip install mkdocs","title":"1.  Make sure you have MkDocs installed"},{"location":"how-to/build-docs/#2-clone-the-git-repository","text":"git clone https://github.com/NCAR/cisl-cloud.git","title":"2.  Clone the git repository"},{"location":"how-to/build-docs/#3-change-in-to-docsdirectory","text":"cd docs/","title":"3.  Change in to docs/directory"},{"location":"how-to/build-docs/#4-serve-content-with-mkdocs","text":"mkdocs serve","title":"4.  Serve content with MkDocs"},{"location":"how-to/build-docs/#documentation-file-structure","text":"mkdocs.yml # The configuration file. docs/ css/ extra.css # Contains extra sytling for the site. how-to/ agile.md # A description of the teams current Agile practices and policies build-docs.md # A how-to on building the documentation website images/ * # All custom images used in the site img/ favicon.ico # Overrides the default images used by readthedocs theme js/ clipboard.js # Javascript to copy code to the clipboard extra.js # Defining how to implement the clipboard copy in our HTML popper.min.js # Used to have the Copied pop up on click tippy-bundle.umd.js # Used to have the Copied pop up on click about.md # The project about trading contact.md # How to interact with the team features.md # A list of potential features for the project index.md # The documentation homepage. layout.md # Outline of site directories and files services.md # List of potential services we will offer","title":"Documentation file structure"},{"location":"how-to/k8sJH/install/","text":"Install JupyterHub on k8s","title":"Install JupyterHub on k8s"},{"location":"how-to/k8sJH/install/#install-jupyterhub-on-k8s","text":"","title":"Install JupyterHub on k8s"},{"location":"overview/about/","text":"About this Project CISL is currently deploying a pilot on-premise prototype cloud environment for compute and storage. 2i2c is potentially going to deploy a JupyterHub instance in AWS for us as well. We would utilize this experience to leverage 2i2c knowledge for our own education. On-premise cloud An on-premise (on-prem) cloud consists of storage, compute, and networking resources hosted on fully redundant hardware installed in personal/organizational facilities available to users Kubernetes (k8s) We will utilize a k8s cluster to host JupyterHub. Dask will be installed to enable parallel computing. A JupyterHub Spawner will create single user environments with access to a shared and personal storage space. The Spawned user environments will come in different sizes with a GPU option. k8s can also be used to host containers or containerized virtual machines for individual use cases. Storage GLADE NFS will be utilized to provide at least RO only access to GLADE on the Spawned JupyterHub user environments. STRATUS S3 will be provided via CISLs object storage platform STRATUS . 2i2c JupyterHub 2i2c will potentially deploy a JupyterHub instance in AWS. Access to this JupyterHub instance will be provided by GitHub Teams. Storage Data Storage for the 2i2c JupyterHub instance is provided by AWS Elastic File System ( EFS ) Data Access AWS S3 Open Data Registry utilizes AWS S3 API calls the same way as STRATUS. By utilizing S3 API calls we can make Data accessible in a familiar way on the Web and on-premise. Agile Program Management Kanban Board This project is implementing a hybrid Agile Project Management workflow. Waterfall techniques will be used for high level project management. Kanban will be used for day to day tasks and creating a continuous flow of value to users.","title":"About"},{"location":"overview/about/#about-this-project","text":"CISL is currently deploying a pilot on-premise prototype cloud environment for compute and storage. 2i2c is potentially going to deploy a JupyterHub instance in AWS for us as well. We would utilize this experience to leverage 2i2c knowledge for our own education.","title":"About this Project"},{"location":"overview/about/#on-premise-cloud","text":"An on-premise (on-prem) cloud consists of storage, compute, and networking resources hosted on fully redundant hardware installed in personal/organizational facilities available to users","title":"On-premise cloud"},{"location":"overview/about/#kubernetes-k8s","text":"We will utilize a k8s cluster to host JupyterHub. Dask will be installed to enable parallel computing. A JupyterHub Spawner will create single user environments with access to a shared and personal storage space. The Spawned user environments will come in different sizes with a GPU option. k8s can also be used to host containers or containerized virtual machines for individual use cases.","title":"Kubernetes (k8s)"},{"location":"overview/about/#storage","text":"","title":"Storage"},{"location":"overview/about/#glade","text":"NFS will be utilized to provide at least RO only access to GLADE on the Spawned JupyterHub user environments.","title":"GLADE"},{"location":"overview/about/#stratus","text":"S3 will be provided via CISLs object storage platform STRATUS .","title":"STRATUS"},{"location":"overview/about/#2i2c","text":"","title":"2i2c"},{"location":"overview/about/#jupyterhub","text":"2i2c will potentially deploy a JupyterHub instance in AWS. Access to this JupyterHub instance will be provided by GitHub Teams.","title":"JupyterHub"},{"location":"overview/about/#storage_1","text":"Data Storage for the 2i2c JupyterHub instance is provided by AWS Elastic File System ( EFS )","title":"Storage"},{"location":"overview/about/#data-access","text":"AWS S3 Open Data Registry utilizes AWS S3 API calls the same way as STRATUS. By utilizing S3 API calls we can make Data accessible in a familiar way on the Web and on-premise.","title":"Data Access"},{"location":"overview/about/#agile-program-management","text":"Kanban Board This project is implementing a hybrid Agile Project Management workflow. Waterfall techniques will be used for high level project management. Kanban will be used for day to day tasks and creating a continuous flow of value to users.","title":"Agile Program Management"},{"location":"overview/availability/","text":"Available Services and Status Virtualization Kubernetes (k8s) We have a kubernetes cluster that we can utilize to host containers. We can provide users a private namespace to deploy to. We can also provision full kubernetes clusters for users via Rancher. Users would be administrators of their own k8s clusters but would have more freedom to customize to their needs and requirements. Virtual Machines (VMs) We can provide VMs to users as needed for tasks that aren't well suited for running in a container. Storage NFS We can provide general shared storage in the form of an NFS volume. Access to these systems is restricted by IP address and mounting is limited to on-premise machines. NFS mounting across wide area networks is not recommended. Object Storage Object Storage is available and our admins can create new buckets and assign user permissions for S3 interactions. Network Services Our systems will have routable IP addresses assigned and configured via DHCP. DNS records can also be added to provide full name resolution for systems provided.","title":"Current Offering"},{"location":"overview/availability/#available-services-and-status","text":"","title":"Available Services and Status"},{"location":"overview/availability/#virtualization","text":"","title":"Virtualization"},{"location":"overview/availability/#kubernetes-k8s","text":"We have a kubernetes cluster that we can utilize to host containers. We can provide users a private namespace to deploy to. We can also provision full kubernetes clusters for users via Rancher. Users would be administrators of their own k8s clusters but would have more freedom to customize to their needs and requirements.","title":"Kubernetes (k8s)"},{"location":"overview/availability/#virtual-machines-vms","text":"We can provide VMs to users as needed for tasks that aren't well suited for running in a container.","title":"Virtual Machines (VMs)"},{"location":"overview/availability/#storage","text":"","title":"Storage"},{"location":"overview/availability/#nfs","text":"We can provide general shared storage in the form of an NFS volume. Access to these systems is restricted by IP address and mounting is limited to on-premise machines. NFS mounting across wide area networks is not recommended.","title":"NFS"},{"location":"overview/availability/#object-storage","text":"Object Storage is available and our admins can create new buckets and assign user permissions for S3 interactions.","title":"Object Storage"},{"location":"overview/availability/#network-services","text":"Our systems will have routable IP addresses assigned and configured via DHCP. DNS records can also be added to provide full name resolution for systems provided.","title":"Network Services"},{"location":"overview/contact/","text":"Contact Us New requests Any new request should be submitted via a Jira Ticket . It will then follow our Kanban workflow . Technical Product Owner The Product Owner (PO), currently Nick Cote , is available via email or Google Chat to discuss any other needs you may have. Interacting with key stakeholders is the primary focus of the PO. They are more than happy to work with you as the primary interface for the technical team. GitHub We have a private GitHub repository to host all of the configuration files and documentation outlined here. It is part of our internal continuous improvement process. It will be eventually opened up for more collaborative efforts.","title":"Contact Us"},{"location":"overview/contact/#contact-us","text":"","title":"Contact Us"},{"location":"overview/contact/#new-requests","text":"Any new request should be submitted via a Jira Ticket . It will then follow our Kanban workflow .","title":"New requests"},{"location":"overview/contact/#technical-product-owner","text":"The Product Owner (PO), currently Nick Cote , is available via email or Google Chat to discuss any other needs you may have. Interacting with key stakeholders is the primary focus of the PO. They are more than happy to work with you as the primary interface for the technical team.","title":"Technical Product Owner"},{"location":"overview/contact/#github","text":"We have a private GitHub repository to host all of the configuration files and documentation outlined here. It is part of our internal continuous improvement process. It will be eventually opened up for more collaborative efforts.","title":"GitHub"},{"location":"overview/features/","text":"Potential CCPP Features JupyterHub On-Prem 2i2c Provided AWS Instance BinderHub Web Hosting Tutorials Data Access Logging/Metrics Documentation Backups/DR RFE\u2019s SLA\u2019s","title":"Potential Features"},{"location":"overview/features/#potential-ccpp-features","text":"","title":"Potential CCPP Features"},{"location":"overview/features/#jupyterhub","text":"","title":"JupyterHub"},{"location":"overview/features/#on-prem","text":"","title":"On-Prem"},{"location":"overview/features/#2i2c-provided-aws-instance","text":"","title":"2i2c Provided AWS Instance"},{"location":"overview/features/#binderhub","text":"","title":"BinderHub"},{"location":"overview/features/#web-hosting","text":"","title":"Web Hosting"},{"location":"overview/features/#tutorials","text":"","title":"Tutorials"},{"location":"overview/features/#data-access","text":"","title":"Data Access"},{"location":"overview/features/#loggingmetrics","text":"","title":"Logging/Metrics"},{"location":"overview/features/#documentation","text":"","title":"Documentation"},{"location":"overview/features/#backupsdr","text":"","title":"Backups/DR"},{"location":"overview/features/#rfes","text":"","title":"RFE\u2019s"},{"location":"overview/features/#slas","text":"","title":"SLA\u2019s"},{"location":"overview/hw-resources/","text":"Hardware Resources Initial Resource (5/1/23) Compute Resources QTY Manufacturer Model CPU Type CPU Speed CPU Cores RAM (GB) GPU Model GPU Cores GPU Memory NICs Storage 5 Supermicro SYS-120U-TNR Intel Xeon Gold 6326 2.90 GHz 16 512 Nvidia A2 Tensor 1280 16 GB 2x10G & 4x25G 2x100GB & 6x1.6TB NVMe Totals CPU Cores RAM GPU Cores GPU Mem Local Storage 80 2.5 TB 6400 80 GB 48 TB Storage Resources STRATUS GLADE (RO) NFS LOCAL 3.3 PB 38 PB 110 TB 48 TB Network Resources","title":"Hardware"},{"location":"overview/hw-resources/#hardware-resources","text":"","title":"Hardware Resources"},{"location":"overview/hw-resources/#initial-resource-5123","text":"","title":"Initial Resource (5/1/23)"},{"location":"overview/hw-resources/#compute-resources","text":"QTY Manufacturer Model CPU Type CPU Speed CPU Cores RAM (GB) GPU Model GPU Cores GPU Memory NICs Storage 5 Supermicro SYS-120U-TNR Intel Xeon Gold 6326 2.90 GHz 16 512 Nvidia A2 Tensor 1280 16 GB 2x10G & 4x25G 2x100GB & 6x1.6TB NVMe","title":"Compute Resources"},{"location":"overview/hw-resources/#totals","text":"CPU Cores RAM GPU Cores GPU Mem Local Storage 80 2.5 TB 6400 80 GB 48 TB","title":"Totals"},{"location":"overview/hw-resources/#storage-resources","text":"STRATUS GLADE (RO) NFS LOCAL 3.3 PB 38 PB 110 TB 48 TB","title":"Storage Resources"},{"location":"overview/hw-resources/#network-resources","text":"","title":"Network Resources"},{"location":"overview/services/","text":"Potential Services offered JupyterHub On-Prem Jupyter notebook servers with multiple pre-determined resources. Web hosting for authorized access. 2i2c Provided AWS Instance Jupyter notebook servers with multiple pre-determined resources. Web hosting for authorized access. BinderHub Users get custom links to recreate environments on CISL on-premise or 2i2c JupyterHub. Provide a public or private Container Registry to host images created from GitHub repository. Web Hosting Visualization Documentation Offer dynamic or static web hosting. Provide unique publicly resolvable DNS names as defined by the user. Tutorials Control student access to available resources. Provide students with identical base image to level set starting point. Provision and tear down student workspaces in a quick and user friendly fashion. Allow console sharing & viewing to assist instructor troubleshooting. Data Access GLADE Read Only A read only NFS mount will be provided for us to utilize in providing access to datasets host on GLADE. STRATUS S3 buckets We will be Administrators for allocated space on STRAUS and will manage buckets and users. API access to buckets in the same fashion as AWS provide a familiar interface. Buckets can be used to host terraform state files if we decide to go that route. API We can utilize STRATUS and other offerings to create APIs to interact programmatically with datasets. File Sharing Offer a central location where model output and other data that has historically been hard to transfer can be served more easily to the users preferred location. Logging/Metrics Provide interactive dashboards for compute, storage, and networking resources. Log all user interactions with our services in order to provide utilization and usage numbers. Make a determination for on-premise service feasibility based on the information collected. Performance on the teams ability to meet Service Level Agreements (SLAs) will be recorded. Documentation Overall vision and goals will be presented as the project evolves to provide full visibility in to the objectives. Implementation of all systems will be documented with code so that someone unfamiliar with the project could recreate the environment. Interactions with cloud offerings will be documented fully so that end users know what services are offered and how to obtain or use those services. Service Level Agreements (SLAs) will be provided so that users know what level of service they can expect with their implementation. Provide details on Agile implementation and how to work with the team via that implementation. Service Level Agreements (SLAs) Defines and documents the operating procedures and commitments between providers and users. SLAs will be defined and documented for each service so users and maintainers can operate with the same expectations. Backups/Disaster Recovery (DR) Each supported service will have an associated and documented Backup and DR policy as part of the SLAs. Request For Enhancement (RFEs) Users will have an avenue for submitting RFEs and that process will be documented.","title":"Potential Services"},{"location":"overview/services/#potential-services-offered","text":"","title":"Potential Services offered"},{"location":"overview/services/#jupyterhub","text":"","title":"JupyterHub"},{"location":"overview/services/#on-prem","text":"Jupyter notebook servers with multiple pre-determined resources. Web hosting for authorized access.","title":"On-Prem"},{"location":"overview/services/#2i2c-provided-aws-instance","text":"Jupyter notebook servers with multiple pre-determined resources. Web hosting for authorized access.","title":"2i2c Provided AWS Instance"},{"location":"overview/services/#binderhub","text":"Users get custom links to recreate environments on CISL on-premise or 2i2c JupyterHub. Provide a public or private Container Registry to host images created from GitHub repository.","title":"BinderHub"},{"location":"overview/services/#web-hosting","text":"","title":"Web Hosting"},{"location":"overview/services/#visualization","text":"","title":"Visualization"},{"location":"overview/services/#documentation","text":"Offer dynamic or static web hosting. Provide unique publicly resolvable DNS names as defined by the user.","title":"Documentation"},{"location":"overview/services/#tutorials","text":"Control student access to available resources. Provide students with identical base image to level set starting point. Provision and tear down student workspaces in a quick and user friendly fashion. Allow console sharing & viewing to assist instructor troubleshooting.","title":"Tutorials"},{"location":"overview/services/#data-access","text":"","title":"Data Access"},{"location":"overview/services/#glade-read-only","text":"A read only NFS mount will be provided for us to utilize in providing access to datasets host on GLADE.","title":"GLADE Read Only"},{"location":"overview/services/#stratus-s3-buckets","text":"We will be Administrators for allocated space on STRAUS and will manage buckets and users. API access to buckets in the same fashion as AWS provide a familiar interface. Buckets can be used to host terraform state files if we decide to go that route.","title":"STRATUS S3 buckets"},{"location":"overview/services/#api","text":"We can utilize STRATUS and other offerings to create APIs to interact programmatically with datasets.","title":"API"},{"location":"overview/services/#file-sharing","text":"Offer a central location where model output and other data that has historically been hard to transfer can be served more easily to the users preferred location.","title":"File Sharing"},{"location":"overview/services/#loggingmetrics","text":"Provide interactive dashboards for compute, storage, and networking resources. Log all user interactions with our services in order to provide utilization and usage numbers. Make a determination for on-premise service feasibility based on the information collected. Performance on the teams ability to meet Service Level Agreements (SLAs) will be recorded.","title":"Logging/Metrics"},{"location":"overview/services/#documentation_1","text":"Overall vision and goals will be presented as the project evolves to provide full visibility in to the objectives. Implementation of all systems will be documented with code so that someone unfamiliar with the project could recreate the environment. Interactions with cloud offerings will be documented fully so that end users know what services are offered and how to obtain or use those services. Service Level Agreements (SLAs) will be provided so that users know what level of service they can expect with their implementation. Provide details on Agile implementation and how to work with the team via that implementation.","title":"Documentation"},{"location":"overview/services/#service-level-agreements-slas","text":"Defines and documents the operating procedures and commitments between providers and users. SLAs will be defined and documented for each service so users and maintainers can operate with the same expectations.","title":"Service Level Agreements (SLAs)"},{"location":"overview/services/#backupsdisaster-recovery-dr","text":"Each supported service will have an associated and documented Backup and DR policy as part of the SLAs.","title":"Backups/Disaster Recovery (DR)"},{"location":"overview/services/#request-for-enhancement-rfes","text":"Users will have an avenue for submitting RFEs and that process will be documented.","title":"Request For Enhancement (RFEs)"},{"location":"overview/use-cases/","text":"Use Cases Running Tutorials An on-premise cloud would allow hosting of user tutorials in an environment controlled by the organization. Access to systems would be controlled by administrators and tutorial leaders in a programmatic way speeding up the on-boarding and off-boarding process. Golden images that allow an identical starting point for each tutorial would be hosted on shared storage. These images would be deployed and assigned to users in a programmatic way by administrators and tutorial leaders. Remote viewing access for users and administrators simultaneously would also create an environment where it was easier to help troubleshoot issues during the tutorials. If possible this would be best done on a Web UI as trying to use SSH and VNC. Jupyter Services JupyterHub is running on a bare metal kubernetes (k8s) cluster deployed with Rancher RKE2. This instance will have authentication for individual users. A user will be able to select from a few different sized environments, some offering GPU capabilities, and a new instance will be spun up with KubeSpawner from a base image. The base image will contain a few common kernels and packages but users will be able to customize their instance with the packages they require. Shared storage will be provided with a unique directory for each user to keep their files. GLADE read-only access will also be provided to each instance so datasets can be accessed from an internal nearby location. Dask services will also be provided in the form of dask.distributed, dask-kubernetes, dask-gateway, and dask-jobqueue for running against HPC resources. Web based visualization capabilities will also be provided but access to these websites hosted via JupyterHub will be limited to authorized users of the JupyterHub instance. Dask on JupyterHub Dask dashboard can be used to view resource utilization and is automatically started via Bokeh once a Dask scheduler is created. Dask Arrays can be used in place of NumPy for parallelized processing of larger-than-memory Arrays. Dask DataFrames can be used in place of pandas for parallelized processing of larger-than-memory DataFrames. Utilize Xarray open_mfdataset & parallel=True to open multiple files as a single Xarray dataset in parallel with Dask Delayed. Dask Distributed can be utilized to create a local Dask Cluster or utilize HPC resources via dask-jobqueue. Running Project Pythia cookbooks such as this one . This notebook utilizes Xarray, Dask Array and Distributed together to allow calculation of the Meridional Overturning Circulation for a series of high resolution projections of ocean state under a climate change scenarios. GPUs on JupyterHub GPU enabled Jupyter notebook servers can be provided to users who want to take advantage of parallel processing on GPU cores. Dask distributed will also be able to create workers with GPUs in order to utilize python modules like RAPIDS and CuPy. Data Access GLADE Access GLADE Access will be provided to JupyterHub instances for users to read GLADE datasets in a close location. An NFS mount to other resources hosted on CISL on-prem cloud hardware may be made available as well. Object Storage CISL provides an Object Storage system named STRATUS with an API available to access S3 buckets in the same fashion as AWS. STRATUS will be utilized to provide API access to required datasets as well as possibly hosting terraform state files used in creating other user resources. Administrators on our STRATUS implementation will be responsible for user management and the creation and maintenance of new buckets. An elastic and flexible catalog for datasets will be implemented with preview or thumbnail methods to ensure access to the correct datasets. Uncoupling large datasets in to individual components will be part of the implementation process. Shared Storage Shared Storage will be provided to JupyterHub instances via the NFS protocol. Access to these mounts from other resources hosted on CISL on-prem cloud hardware may be made available as well. Local Transfers A method to allow for quick and easy data & output transfers to local systems will be provided with detailed instructions. Web Visualization Hosting Real time interactive and customizable web visualizations will be hosted in various methods on CISL infrastructure. Applications such as Bokeh, Panel, Viola, etc. can host interactive visualizations from Jupyter Notebooks or Python applications. Users will be provided with a programmatic way to deploy these applications with public or private URLs in a stable highly available environment. File Sharing The CISL on-prem infrastructure provides a location that is easier to access and share information and files. Applications like NextCloud can be provisioned to host file sharing services. Creating k8s clusters Rancher is part of the on-prem software stack and can be utilized to provision users their own k8s cluster for development or production use cases. Access to most storage resources can also be provided in these deployments. Hosting Containerized Applications Users will be able to deploy their containerized applications in to the k8s cluster which provides a highly available and accessible hosting location. Smaller individual JupyterLab containers can be provisioned with the ability to host public facing web visualizations via notebooks and code running in the JupyterLab containers. Hosting Virtual Machines (VMs) If needed, VM's can also be provided either from pre configured templates or as bare instances and will be hosted either in a VMware cluster or the k8s cluster.","title":"Use Cases"},{"location":"overview/use-cases/#use-cases","text":"","title":"Use Cases"},{"location":"overview/use-cases/#running-tutorials","text":"An on-premise cloud would allow hosting of user tutorials in an environment controlled by the organization. Access to systems would be controlled by administrators and tutorial leaders in a programmatic way speeding up the on-boarding and off-boarding process. Golden images that allow an identical starting point for each tutorial would be hosted on shared storage. These images would be deployed and assigned to users in a programmatic way by administrators and tutorial leaders. Remote viewing access for users and administrators simultaneously would also create an environment where it was easier to help troubleshoot issues during the tutorials. If possible this would be best done on a Web UI as trying to use SSH and VNC.","title":"Running Tutorials"},{"location":"overview/use-cases/#jupyter-services","text":"JupyterHub is running on a bare metal kubernetes (k8s) cluster deployed with Rancher RKE2. This instance will have authentication for individual users. A user will be able to select from a few different sized environments, some offering GPU capabilities, and a new instance will be spun up with KubeSpawner from a base image. The base image will contain a few common kernels and packages but users will be able to customize their instance with the packages they require. Shared storage will be provided with a unique directory for each user to keep their files. GLADE read-only access will also be provided to each instance so datasets can be accessed from an internal nearby location. Dask services will also be provided in the form of dask.distributed, dask-kubernetes, dask-gateway, and dask-jobqueue for running against HPC resources. Web based visualization capabilities will also be provided but access to these websites hosted via JupyterHub will be limited to authorized users of the JupyterHub instance.","title":"Jupyter Services"},{"location":"overview/use-cases/#dask-on-jupyterhub","text":"Dask dashboard can be used to view resource utilization and is automatically started via Bokeh once a Dask scheduler is created. Dask Arrays can be used in place of NumPy for parallelized processing of larger-than-memory Arrays. Dask DataFrames can be used in place of pandas for parallelized processing of larger-than-memory DataFrames. Utilize Xarray open_mfdataset & parallel=True to open multiple files as a single Xarray dataset in parallel with Dask Delayed. Dask Distributed can be utilized to create a local Dask Cluster or utilize HPC resources via dask-jobqueue. Running Project Pythia cookbooks such as this one . This notebook utilizes Xarray, Dask Array and Distributed together to allow calculation of the Meridional Overturning Circulation for a series of high resolution projections of ocean state under a climate change scenarios.","title":"Dask on JupyterHub"},{"location":"overview/use-cases/#gpus-on-jupyterhub","text":"GPU enabled Jupyter notebook servers can be provided to users who want to take advantage of parallel processing on GPU cores. Dask distributed will also be able to create workers with GPUs in order to utilize python modules like RAPIDS and CuPy.","title":"GPUs on JupyterHub"},{"location":"overview/use-cases/#data-access","text":"","title":"Data Access"},{"location":"overview/use-cases/#glade-access","text":"GLADE Access will be provided to JupyterHub instances for users to read GLADE datasets in a close location. An NFS mount to other resources hosted on CISL on-prem cloud hardware may be made available as well.","title":"GLADE Access"},{"location":"overview/use-cases/#object-storage","text":"CISL provides an Object Storage system named STRATUS with an API available to access S3 buckets in the same fashion as AWS. STRATUS will be utilized to provide API access to required datasets as well as possibly hosting terraform state files used in creating other user resources. Administrators on our STRATUS implementation will be responsible for user management and the creation and maintenance of new buckets. An elastic and flexible catalog for datasets will be implemented with preview or thumbnail methods to ensure access to the correct datasets. Uncoupling large datasets in to individual components will be part of the implementation process.","title":"Object Storage"},{"location":"overview/use-cases/#shared-storage","text":"Shared Storage will be provided to JupyterHub instances via the NFS protocol. Access to these mounts from other resources hosted on CISL on-prem cloud hardware may be made available as well.","title":"Shared Storage"},{"location":"overview/use-cases/#local-transfers","text":"A method to allow for quick and easy data & output transfers to local systems will be provided with detailed instructions.","title":"Local Transfers"},{"location":"overview/use-cases/#web-visualization-hosting","text":"Real time interactive and customizable web visualizations will be hosted in various methods on CISL infrastructure. Applications such as Bokeh, Panel, Viola, etc. can host interactive visualizations from Jupyter Notebooks or Python applications. Users will be provided with a programmatic way to deploy these applications with public or private URLs in a stable highly available environment.","title":"Web Visualization Hosting"},{"location":"overview/use-cases/#file-sharing","text":"The CISL on-prem infrastructure provides a location that is easier to access and share information and files. Applications like NextCloud can be provisioned to host file sharing services.","title":"File Sharing"},{"location":"overview/use-cases/#creating-k8s-clusters","text":"Rancher is part of the on-prem software stack and can be utilized to provision users their own k8s cluster for development or production use cases. Access to most storage resources can also be provided in these deployments.","title":"Creating k8s clusters"},{"location":"overview/use-cases/#hosting-containerized-applications","text":"Users will be able to deploy their containerized applications in to the k8s cluster which provides a highly available and accessible hosting location. Smaller individual JupyterLab containers can be provisioned with the ability to host public facing web visualizations via notebooks and code running in the JupyterLab containers.","title":"Hosting Containerized Applications"},{"location":"overview/use-cases/#hosting-virtual-machines-vms","text":"If needed, VM's can also be provided either from pre configured templates or as bare instances and will be hosted either in a VMware cluster or the k8s cluster.","title":"Hosting Virtual Machines (VMs)"}]}